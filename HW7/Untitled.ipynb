{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  tsne.py\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pylab\n",
    "import os\n",
    "\n",
    "\n",
    "def load_data(X_filename, label_filename):\n",
    "    print('load data.....')\n",
    "    print(X_filename[:-4])\n",
    "    X_file = X_filename[:-4]\n",
    "    label_file = label_filename[:-4]\n",
    "    # exit()\n",
    "    # Implement load data related codes here\n",
    "    if os.path.exists(X_file + '.npy'):\n",
    "        data = np.load(X_file + '.npy')\n",
    "    else:\n",
    "        data = np.loadtxt(X_filename, delimiter=',')\n",
    "        np.save(X_file, data)\n",
    "\n",
    "    if os.path.exists(label_file + '.npy'):\n",
    "        label = np.load(label_file + '.npy')\n",
    "    else:\n",
    "        label = np.loadtxt(label_filename, delimiter=',')\n",
    "        np.save(label_file, data)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Hbeta(D=np.array([]), beta=1.0):\n",
    "    \"\"\"\n",
    "        Compute the perplexity and the P-row for a specific value of the\n",
    "        precision of a Gaussian distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute P-row and corresponding perplexity\n",
    "    P = np.exp(-D.copy() * beta)\n",
    "    sumP = sum(P)\n",
    "    H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "    P = P / sumP\n",
    "    return H, P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x2p(X=np.array([]), tol=1e-5, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Performs a binary search to get P-values in such a way that each\n",
    "        conditional Gaussian has the same perplexity.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize some variables\n",
    "    print(\"Computing pairwise distances...\")\n",
    "    (n, d) = X.shape\n",
    "    sum_X = np.sum(np.square(X), 1)\n",
    "    D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T, sum_X)\n",
    "    P = np.zeros((n, n))\n",
    "    beta = np.ones((n, 1))\n",
    "    logU = np.log(perplexity)\n",
    "\n",
    "    # Loop over all datapoints\n",
    "    for i in range(n):\n",
    "\n",
    "        # Print progress\n",
    "        if i % 500 == 0:\n",
    "            print(\"Computing P-values for point %d of %d...\" % (i, n))\n",
    "\n",
    "        # Compute the Gaussian kernel and entropy for the current precision\n",
    "        betamin = -np.inf\n",
    "        betamax = np.inf\n",
    "        Di = D[i, np.concatenate((np.r_[0:i], np.r_[i + 1:n]))]\n",
    "        (H, thisP) = Hbeta(Di, beta[i])\n",
    "\n",
    "        # Evaluate whether the perplexity is within tolerance\n",
    "        Hdiff = H - logU\n",
    "        tries = 0\n",
    "        while np.abs(Hdiff) > tol and tries < 50:\n",
    "\n",
    "            # If not, increase or decrease precision\n",
    "            if Hdiff > 0:\n",
    "                betamin = beta[i].copy()\n",
    "                if betamax == np.inf or betamax == -np.inf:\n",
    "                    beta[i] = beta[i] * 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamax) / 2.\n",
    "            else:\n",
    "                betamax = beta[i].copy()\n",
    "                if betamin == np.inf or betamin == -np.inf:\n",
    "                    beta[i] = beta[i] / 2.\n",
    "                else:\n",
    "                    beta[i] = (beta[i] + betamin) / 2.\n",
    "\n",
    "            # Recompute the values\n",
    "            (H, thisP) = Hbeta(Di, beta[i])\n",
    "            Hdiff = H - logU\n",
    "            tries += 1\n",
    "\n",
    "        # Set the final row of P\n",
    "        P[i, np.concatenate((np.r_[0:i], np.r_[i + 1:n]))] = thisP\n",
    "\n",
    "    # Return final P-matrix\n",
    "    print(\"Mean value of sigma: %f\" % np.mean(np.sqrt(1 / beta)))\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca(X=np.array([]), no_dims=50):\n",
    "    \"\"\"\n",
    "        Runs PCA on the NxD array X in order to reduce its dimensionality to\n",
    "        no_dims dimensions.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Preprocessing the data using PCA...\")\n",
    "\n",
    "    # Implement PCA here\n",
    "    def mean(data):\n",
    "        return np.mean(data, axis=1)\n",
    "\n",
    "    def scatter_matrix(data):\n",
    "        \"\"\" S = sum((Xk-m)@(Xk-m)^T) / n, where k=1,...,n \"\"\"\n",
    "        return np.cov(data, bias=True)\n",
    "\n",
    "    def find_k_largest_eigenvalues(cov):\n",
    "        k = no_dims\n",
    "        eigen_value, eigen_vector = np.linalg.eig(cov)\n",
    "        sorting_index = np.argsort(-eigen_value)\n",
    "        eigen_value = eigen_value[sorting_index]\n",
    "        eigen_vector = eigen_vector.T[sorting_index]\n",
    "        return eigen_value[0:k], (eigen_vector[0:k])\n",
    "\n",
    "    def transform(W, data):\n",
    "        return W @ data\n",
    "\n",
    "    data = X.T  # (784, 5000)\n",
    "    ### mean ###\n",
    "    mean = mean(data)  # (784,)\n",
    "    print(mean.shape)\n",
    "    ### S(covariance) ###\n",
    "    S = scatter_matrix(data)  #(784, 784)\n",
    "    print(S.shape)\n",
    "    ### eigenvector & eigenvalue -> principle components ###\n",
    "    eigen_value, eigen_vector = find_k_largest_eigenvalues(S)\n",
    "    print('eigen_value:')\n",
    "    print(eigen_value)\n",
    "    print('eigen_vector:')\n",
    "    print(eigen_vector.shape)\n",
    "    ### Now W is eigen_vector (no_dims, 784) ###\n",
    "    transformed_data = np.real(transform(eigen_vector, data))\n",
    "    # np.savetxt('transformed.txt', np.imag(transformed_data))\n",
    "    print('transformed: ', transformed_data.shape)\n",
    "    print(transformed_data)\n",
    "    return transformed_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(X=np.array([]), no_dims=2, initial_dims=50, perplexity=30.0):\n",
    "    \"\"\"\n",
    "        Runs t-SNE on the dataset in the NxD array X to reduce its\n",
    "        dimensionality to no_dims dimensions. The syntaxis of the function is\n",
    "        `Y = tsne.tsne(X, no_dims, perplexity), where X is an NxD NumPy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check inputs\n",
    "    if isinstance(no_dims, float):\n",
    "        print(\"Error: array X should have type float.\")\n",
    "        return -1\n",
    "    if round(no_dims) != no_dims:\n",
    "        print(\"Error: number of dimensions should be an integer.\")\n",
    "        return -1\n",
    "\n",
    "    # Initialize variables\n",
    "    X = pca(X, initial_dims).real\n",
    "    (n, d) = X.shape\n",
    "    max_iter = 400\n",
    "    initial_momentum = 0.5\n",
    "    final_momentum = 0.8\n",
    "    eta = 500\n",
    "    min_gain = 0.01\n",
    "    Y = np.random.randn(n, no_dims)\n",
    "    dY = np.zeros((n, no_dims))\n",
    "    iY = np.zeros((n, no_dims))\n",
    "    gains = np.ones((n, no_dims))\n",
    "\n",
    "    # Compute P-values\n",
    "    P = x2p(X, 1e-5, perplexity)\n",
    "    P = P + np.transpose(P)\n",
    "    P = P / np.sum(P)\n",
    "    P = P * 4.  # early exaggeration\n",
    "    P = np.maximum(P, 1e-12)\n",
    "\n",
    "    # Run iterations\n",
    "    for iter in range(max_iter):\n",
    "\n",
    "        # Compute pairwise affinities\n",
    "        sum_Y = np.sum(np.square(Y), 1)\n",
    "        num = -2. * np.dot(Y, Y.T)\n",
    "        num = 1. / (1. + np.add(np.add(num, sum_Y).T, sum_Y))\n",
    "        num[range(n), range(n)] = 0.\n",
    "        Q = num / np.sum(num)\n",
    "        Q = np.maximum(Q, 1e-12)\n",
    "\n",
    "        # Compute gradient\n",
    "        PQ = P - Q\n",
    "        for i in range(n):\n",
    "            dY[i, :] = np.sum(\n",
    "                np.tile(PQ[:, i] * num[:, i], (no_dims, 1)).T * (Y[i, :] - Y),\n",
    "                0)\n",
    "\n",
    "        # Perform the update\n",
    "        if iter < 20:\n",
    "            momentum = initial_momentum\n",
    "        else:\n",
    "            momentum = final_momentum\n",
    "        gains = (gains + 0.2) * ((dY > 0.) != (iY > 0.)) + \\\n",
    "                (gains * 0.8) * ((dY > 0.) == (iY > 0.))\n",
    "        gains[gains < min_gain] = min_gain\n",
    "        iY = momentum * iY - eta * (gains * dY)\n",
    "        Y = Y + iY\n",
    "        Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "\n",
    "        # Compute current value of cost function\n",
    "        if (iter + 1) % 10 == 0:\n",
    "            C = np.sum(P * np.log(P / Q))\n",
    "            print(\"Iteration %d: error is %f\" % (iter + 1, C))\n",
    "\n",
    "        # Stop lying about P-values\n",
    "        if iter == 100:\n",
    "            P = P / 4.\n",
    "\n",
    "    # Return solution\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_dist(D, n_bins=50):\n",
    "    bins = [[] for i in range(n_bins)]\n",
    "\n",
    "    thresholds = [\n",
    "        np.min(D) + i / n_bins * (np.max(D) - np.min(D))\n",
    "        for i in range(n_bins + 1)\n",
    "    ]\n",
    "\n",
    "    for i in range(1, n_bins + 1):\n",
    "        bins[i - 1] = D[(D <= thresholds[i])\n",
    "                        & (D > thresholds[i - 1])].shape[0]\n",
    "\n",
    "    return np.array(bins) / 2, thresholds[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\n",
      "Running example on 2,500 MNIST digits...\n",
      "load data.....\n",
      "mnist_X\n",
      "Preprocessing the data using PCA...\n",
      "(784,)\n",
      "(784, 784)\n",
      "eigen_value:\n",
      "[8.04918878+0.j 4.44770058+0.j 3.43525144+0.j 3.26278806+0.j\n",
      " 2.7804046 +0.j 2.11013737+0.j 1.84025522+0.j 1.44765374+0.j\n",
      " 1.38812259+0.j 1.193162  +0.j 1.08883714+0.j 0.9327465 +0.j\n",
      " 0.8807986 +0.j 0.81231805+0.j 0.77625515+0.j 0.69386989+0.j\n",
      " 0.66941876+0.j 0.61742183+0.j 0.59542722+0.j 0.56244567+0.j\n",
      " 0.5001472 +0.j 0.47957136+0.j 0.47019905+0.j 0.43778355+0.j\n",
      " 0.43040579+0.j 0.40567031+0.j 0.38055975+0.j 0.37081285+0.j\n",
      " 0.35461363+0.j 0.33713058+0.j 0.32477788+0.j 0.3122558 +0.j\n",
      " 0.28073759+0.j 0.27471868+0.j 0.26338429+0.j 0.25775301+0.j\n",
      " 0.25108304+0.j 0.23922053+0.j 0.22587304+0.j 0.22497242+0.j\n",
      " 0.20663082+0.j 0.20563794+0.j 0.20245611+0.j 0.1906108 +0.j\n",
      " 0.18846049+0.j 0.18480074+0.j 0.17821267+0.j 0.17403797+0.j\n",
      " 0.17135392+0.j 0.15805769+0.j]\n",
      "eigen_vector:\n",
      "(50, 784)\n",
      "transformed:  (50, 5000)\n",
      "[[-7.34407232e+00 -7.43639868e+00 -5.28583144e+00 ... -4.71351887e+00\n",
      "  -4.25478574e+00 -3.98893472e+00]\n",
      " [ 2.03868796e+00  2.30094319e+00  1.16848351e+00 ... -3.58177369e+00\n",
      "  -2.54665878e+00 -2.13670960e+00]\n",
      " [-1.78144068e+00 -1.87551412e+00 -4.62608161e+00 ... -1.04703997e+00\n",
      "  -2.81378699e+00 -4.16353490e+00]\n",
      " ...\n",
      " [ 2.99431989e-01 -2.01355874e-01  1.48544446e-01 ... -1.82395753e-01\n",
      "  -2.14206750e-01 -7.09554167e-02]\n",
      " [-1.24336882e-01  1.33336957e-01  1.63309965e-01 ... -1.52198873e-01\n",
      "   3.27328030e-01 -2.05047600e-03]\n",
      " [-2.57332279e-01 -4.18199089e-02  2.51208248e-01 ... -4.18841330e-01\n",
      "   4.85036853e-01  9.19068377e-01]]\n",
      "Computing pairwise distances...\n",
      "Computing P-values for point 0 of 5000...\n",
      "Computing P-values for point 500 of 5000...\n",
      "Computing P-values for point 1000 of 5000...\n",
      "Computing P-values for point 1500 of 5000...\n",
      "Computing P-values for point 2000 of 5000...\n",
      "Computing P-values for point 2500 of 5000...\n",
      "Computing P-values for point 3000 of 5000...\n",
      "Computing P-values for point 3500 of 5000...\n",
      "Computing P-values for point 4000 of 5000...\n",
      "Computing P-values for point 4500 of 5000...\n",
      "Mean value of sigma: 1.799864\n",
      "Iteration 10: error is 26.581053\n",
      "Iteration 20: error is 25.084703\n",
      "Iteration 30: error is 21.233087\n",
      "Iteration 40: error is 19.496740\n",
      "Iteration 50: error is 18.816743\n",
      "Iteration 60: error is 18.522250\n",
      "Iteration 70: error is 18.346439\n",
      "Iteration 80: error is 18.193311\n",
      "Iteration 90: error is 18.080576\n",
      "Iteration 100: error is 18.010528\n",
      "Iteration 110: error is 2.807811\n",
      "Iteration 120: error is 2.634875\n",
      "Iteration 130: error is 2.497576\n",
      "Iteration 140: error is 2.381143\n",
      "Iteration 150: error is 2.281324\n",
      "Iteration 160: error is 2.195423\n",
      "Iteration 170: error is 2.121197\n",
      "Iteration 180: error is 2.056516\n",
      "Iteration 190: error is 1.999867\n",
      "Iteration 200: error is 1.950071\n",
      "Iteration 210: error is 1.906089\n",
      "Iteration 220: error is 1.866722\n",
      "Iteration 230: error is 1.831279\n",
      "Iteration 240: error is 1.799240\n",
      "Iteration 250: error is 1.770138\n",
      "Iteration 260: error is 1.743518\n",
      "Iteration 270: error is 1.719243\n",
      "Iteration 280: error is 1.697017\n",
      "Iteration 290: error is 1.676613\n",
      "Iteration 300: error is 1.657814\n",
      "Iteration 310: error is 1.640421\n",
      "Iteration 320: error is 1.624362\n",
      "Iteration 330: error is 1.609458\n",
      "Iteration 340: error is 1.595627\n",
      "Iteration 350: error is 1.582733\n",
      "Iteration 360: error is 1.570682\n",
      "Iteration 370: error is 1.559363\n",
      "Iteration 380: error is 1.548704\n",
      "Iteration 390: error is 1.538661\n",
      "Iteration 400: error is 1.529162\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-cfa116d9c50f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Running example on 2,500 MNIST digits...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist_X.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mnist_label.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mpylab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpylab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-56e919479ca1>\u001b[0m in \u001b[0;36mtsne\u001b[1;34m(X, no_dims, initial_dims, perplexity)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_dist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_bins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[0mfigure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m     \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m111\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\n",
    "        \"Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.\"\n",
    "    )\n",
    "    print(\"Running example on 2,500 MNIST digits...\")\n",
    "    X, labels = load_data('mnist_X.csv', 'mnist_label.csv')\n",
    "    Y = tsne(X, 2, 50, 20.0)\n",
    "    pylab.scatter(Y[:, 0], Y[:, 1], 20, labels)\n",
    "    pylab.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
